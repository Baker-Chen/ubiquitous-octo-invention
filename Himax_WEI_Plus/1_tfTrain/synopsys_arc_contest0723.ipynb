{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "synopsys_arc_contest.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6fFTHNl_fbLj",
        "gct_AxAsoVSF",
        "1crXaj1Us8Az",
        "lQdVz0KsocrK",
        "VYMRJtCReqgv",
        "bpFV5L7SjHn0",
        "7PK2PMtiflLQ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ax9DzLM7i3E"
      },
      "source": [
        "!rm -rf ./data/trainingData0720"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUvOMG4h95JD"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBTICeTX9rIi"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import random\n",
        "import IPython.display as display\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gc\n",
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import *\n",
        "from keras.activations import *\n",
        "from keras.callbacks import *\n",
        "from functools import partial\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT6CcaqgQewg"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLlVPecM5DyN"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS1WYb9l-qhT"
      },
      "source": [
        "# Set Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwPWfewkGpII"
      },
      "source": [
        "img_rows = 96\n",
        "img_cols = 96\n",
        "n_class = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvJWrH_4AVnw"
      },
      "source": [
        "# Download data from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDX2-oDw-x4m"
      },
      "source": [
        "%%time\n",
        "zip_path = '/content/drive/MyDrive/ARC _AIoT 共用雲端/datasetclearplushand0721.zip'\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q datasetclearplushand0721.zip -d './data'\n",
        "!rm datasetclearplushand0721.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjr5CV-7AkXo"
      },
      "source": [
        "# List all directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN-Pc6Zd6awg"
      },
      "source": [
        "data_root = pathlib.Path('./data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7onR_lWE7Njj"
      },
      "source": [
        "for item in data_root.iterdir():\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dgbZNPc_VX1"
      },
      "source": [
        "all_image_paths = list(data_root.glob('*/*')) \n",
        "all_image_paths = [str(path) for path in all_image_paths]\n",
        "random.shuffle(all_image_paths)\n",
        "\n",
        "image_count = len(all_image_paths)\n",
        "image_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfJ458BKArZD"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1gob9Xc_bIL"
      },
      "source": [
        "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "label_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrgN8NWO_ctB"
      },
      "source": [
        "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
        "label_to_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnyKOvNM_d0C"
      },
      "source": [
        "all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                    for path in all_image_paths]\n",
        "\n",
        "test_labels = to_categorical(all_image_labels, n_class, dtype = 'float32')\n",
        "print(\"First 10 labels indices: \", all_image_labels[:20])\n",
        "# print(test_labels[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLB7TqYo_9bc"
      },
      "source": [
        "def preprocess_image(image):\n",
        "  image = tf.image.decode_jpeg(image, channels=1)\n",
        "  image = tf.image.resize(image, [img_rows, img_cols])\n",
        "\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeWfCzyM_8L_"
      },
      "source": [
        "def load_and_preprocess_image(path):\n",
        "  image = tf.io.read_file(path)\n",
        "  return preprocess_image(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lytMokoQ_ged"
      },
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices((all_image_paths, test_labels))\n",
        "# 元组被解压缩到映射函数的位置参数中\n",
        "def load_and_preprocess_from_path_label(path, label):\n",
        "  return load_and_preprocess_image(path), label\n",
        "\n",
        "image_label = ds.map(load_and_preprocess_from_path_label)\n",
        "print(image_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGofPq7sACoo"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "setDs = image_label.shuffle(buffer_size=image_count)\n",
        "setDs = setDs.repeat()\n",
        "setDs_Batch = setDs.batch(BATCH_SIZE)\n",
        "\n",
        "setDs = setDs.prefetch(buffer_size=AUTOTUNE)\n",
        "print(setDs)\n",
        "print(setDs_Batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDDDSJJvX-u8"
      },
      "source": [
        "## Separate training and testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPRyUdj4LCGX"
      },
      "source": [
        "trainingSet = setDs.skip(int(image_count*0.2))\n",
        "trainingSet_Batch = setDs_Batch.take(int(image_count*0.2))\n",
        "\n",
        "testingSet = setDs.take(int(image_count*0.2))\n",
        "testingSet_Batch = setDs_Batch.take(int(image_count*0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhmpXmrtYNC5"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dl5JEfbBp3X"
      },
      "source": [
        "def plot_dataset(dataset, num=5):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plot_index = 0\n",
        "    for image, label in dataset.take(num):\n",
        "        image = image.numpy()\n",
        "        label = label.numpy()\n",
        "        \n",
        "        plot_index+=1\n",
        "        plt.subplot(3, 5, plot_index)\n",
        "        plt.imshow(image.squeeze(),'gray')\n",
        "\n",
        "plot_dataset(trainingSet, 15)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBjJ1SVKA4dz"
      },
      "source": [
        "# Image Augment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FLpeTEPIxON"
      },
      "source": [
        "pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNE-Ll3TDPLB"
      },
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjvWwWICA9lt"
      },
      "source": [
        "def image_transpose(image):\n",
        "    rand = tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) \n",
        "    image = tf.cond(rand < 0.5, \n",
        "                    lambda: tf.identity(image), \n",
        "                    lambda: tf.image.transpose(image)) \n",
        "    return image\n",
        "\n",
        "def image_flip(image: tf.Tensor) -> tf.Tensor:\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    return image\n",
        "\n",
        "def image_rotate(image):\n",
        "    # image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "    rand = tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) \n",
        "    def random_rotate(image):\n",
        "        image = tfa.image.rotate(\n",
        "            image, tf.random.uniform(shape=[], minval=-30 * np.pi / 180, maxval=30 * np.pi / 180, dtype=tf.float32))\n",
        "        return image\n",
        "    \n",
        "    image = tf.cond(rand < 0.5, \n",
        "                    # lambda: tf.identity(image), \n",
        "                    lambda: random_rotate(image),\n",
        "                    lambda: random_rotate(image)) \n",
        "    return image  \n",
        "\n",
        "def image_color(image: tf.Tensor) -> tf.Tensor:\n",
        "    image = tf.image.random_saturation(image, lower=0.5, upper=3)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1)\n",
        "    image = tf.image.random_hue(image, max_delta=0.03)\n",
        "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
        "    return image\n",
        "\n",
        "def image_inversion(image: tf.Tensor) -> tf.Tensor:\n",
        "    rand = tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "    image = tf.cond(rand < 0.8, \n",
        "                    lambda: tf.identity(image), \n",
        "                    lambda: tf.math.add(tf.math.multiply(image, -1), 1))\n",
        "    return image\n",
        "\n",
        "def image_zoom(image: tf.Tensor, min_zoom=0.8, max_zoom=1.0) -> tf.Tensor:\n",
        "    image_width, image_height, image_colors = image.shape\n",
        "    crop_size = (image_width, image_height)\n",
        "\n",
        "    # Generate crop settings, ranging from a 1% to 20% crop.\n",
        "    scales = list(np.arange(min_zoom, max_zoom, 0.01))\n",
        "    boxes = np.zeros((len(scales), 4))\n",
        "\n",
        "    for i, scale in enumerate(scales):\n",
        "        x1 = y1 = 0.5 - (0.5 * scale)\n",
        "        x2 = y2 = 0.5 + (0.5 * scale)\n",
        "        boxes[i] = [x1, y1, x2, y2]\n",
        "\n",
        "    def random_crop(img):\n",
        "        # Create different crops for an image\n",
        "        crops = tf.image.crop_and_resize(\n",
        "            [img],\n",
        "            boxes=boxes,\n",
        "            box_indices=np.zeros(len(scales)),\n",
        "            crop_size=crop_size\n",
        "        )\n",
        "        # Return a random crop\n",
        "        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
        "\n",
        "    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
        "\n",
        "    # Only apply cropping 50% of the time\n",
        "    return tf.cond(choice < 0.5, lambda: image, lambda: random_crop(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4dbzLHUBEYG"
      },
      "source": [
        "def augment_data(image, label):\n",
        "    # image = image_flip(image)\n",
        "    # image = image_color(image)\n",
        "    # image = image_zoom(image)\n",
        "    # image = image_transpose(image)\n",
        "    image = image_inversion(image)\n",
        "    # image = image_rotate(image)\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLARhFWTYbEH"
      },
      "source": [
        "## Augment Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNa5CVL1Fg_4"
      },
      "source": [
        "trainingSet = trainingSet.map(augment_data)\n",
        "\n",
        "plot_dataset(trainingSet,15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEQbxMNC-jMZ"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fFTHNl_fbLj"
      },
      "source": [
        "## **INCEPTION_NET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edn-aJjFDHTK"
      },
      "source": [
        "conv1x1 = partial(layers.Conv2D, kernel_size=1, activation='relu')\n",
        "conv3x3 = partial(layers.Conv2D, kernel_size=3, padding='same', activation='relu')\n",
        "conv5x5 = partial(layers.Conv2D, kernel_size=5, padding='same', activation='relu')\n",
        "\n",
        "def inception_module(in_tensor, c1, c3_1, c3, c5_1, c5, pp):\n",
        "  conv1 = conv1x1(c1)(in_tensor)\n",
        "  conv3_1 = conv1x1(c3_1)(in_tensor)\n",
        "  conv3 = conv3x3(c3)(conv3_1) \n",
        "  conv5_1 = conv1x1(c5_1)(in_tensor) \n",
        "  conv5 = conv5x5(c5)(conv5_1) \n",
        "  pool_conv = conv1x1(pp)(in_tensor) \n",
        "  pool = layers.MaxPool2D(3, strides=1, padding='same')(pool_conv) \n",
        "  merged = layers.Concatenate(axis=-1)([conv1, conv3, conv5, pool]) \n",
        "  return merged \n",
        "\n",
        "def aux_clf(in_tensor): \n",
        "  avg_pool = layers.AvgPool2D(5, 3)(in_tensor)\n",
        "  conv = conv1x1(128)(avg_pool)\n",
        "  flattened = layers.Flatten()(conv)\n",
        "  dense = layers.Dense(1024, activation='relu')(flattened)\n",
        "  dropout = layers.Dropout(0.7)(dense)\n",
        "  out = layers.Dense(n_class, activation='softmax')(dropout)\n",
        "  return out\n",
        "\n",
        "def inception_net(in_shape=(224,224,3), n_classes=1000, opt='sgd'): \n",
        "  in_layer = layers.Input(in_shape) \n",
        "  rescale = layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  conv1 = layers.Conv2D(64, 7, strides=2, activation='relu', padding='same')(in_layer) \n",
        "  pad1 = layers.ZeroPadding2D()(conv1) \n",
        "  pool1 = layers.MaxPool2D(3, 2)(pad1) \n",
        "  conv2_1 = conv1x1(64)(pool1) \n",
        "  conv2_2 = conv3x3(192)(conv2_1) \n",
        "  pad2 = layers.ZeroPadding2D()(conv2_2) \n",
        "  pool2 = layers.MaxPool2D(3, 2)(pad2) \n",
        "  inception3a = inception_module(pool2, 64, 96, 128, 16, 32, 32) \n",
        "  inception3b = inception_module(inception3a, 128, 128, 192, 32, 96, 64) \n",
        "  pad3 = layers.ZeroPadding2D()(inception3b) \n",
        "  pool3 = layers.MaxPool2D(3, 2)(pad3) \n",
        "  inception4a = inception_module(pool3, 192, 96, 208, 16, 48, 64) \n",
        "  inception4b = inception_module(inception4a, 160, 112, 224, 24, 64, 64) \n",
        "  inception4c = inception_module(inception4b, 128, 128, 256, 24, 64, 64) \n",
        "  inception4d = inception_module(inception4c, 112, 144, 288, 32, 48, 64) \n",
        "  inception4e = inception_module(inception4d, 256, 160, 320, 32, 128, 128) \n",
        "  pad4 = layers.ZeroPadding2D()(inception4e) \n",
        "  pool4 = layers.MaxPool2D(3, 2)(pad4) \n",
        "  aux_clf1 = aux_clf(inception4a) \n",
        "  aux_clf2 = aux_clf(inception4d) \n",
        "  inception5a = inception_module(pool4, 256, 160, 320, 32, 128, 128) \n",
        "  inception5b = inception_module(inception5a, 384, 192, 384, 48, 128, 128) \n",
        "  pad5 = layers.ZeroPadding2D()(inception5b) \n",
        "  pool5 = layers.MaxPool2D(3, 2)(pad5) \n",
        "  avg_pool = layers.GlobalAvgPool2D()(pool5) \n",
        "  dropout = layers.Dropout(0.4)(avg_pool) \n",
        "  preds = layers.Dense(n_class, activation='softmax')(dropout) \n",
        "  model = Model(in_layer, [preds, aux_clf1, aux_clf2]) \n",
        "  # model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]) \n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSHBFO8TDHTM"
      },
      "source": [
        "model = inception_net(in_shape=(img_rows, img_cols, 1), n_classes=n_class) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gct_AxAsoVSF"
      },
      "source": [
        "## Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpa_gB-6XXv6"
      },
      "source": [
        "\n",
        "backend = None\n",
        "models = None\n",
        "keras_utils = None\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    # if backend.image_data_format() == 'channels_last':\n",
        "    #     bn_axis = 3\n",
        "    # else:\n",
        "    #     bn_axis = 1\n",
        "    bn_axis = 1\n",
        "    \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    # if backend.image_data_format() == 'channels_last':\n",
        "    #     bn_axis = 3\n",
        "    # else:\n",
        "    #     bn_axis = 1\n",
        "\n",
        "    bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=10,\n",
        "             **kwargs):\n",
        "    \"\"\"Instantiates the ResNet50 architecture.\n",
        "    Optionally loads weights pre-trained on ImageNet.\n",
        "    Note that the data format convention used by the model is\n",
        "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
        "    # Arguments\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
        "            or `(3, 224, 224)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 32.\n",
        "            E.g. `(200, 200, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional block.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional block, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "    global backend, layers, models, keras_utils\n",
        "    # backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
        "\n",
        "    bn_axis = 1\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    # if backend.image_data_format() == 'channels_last':\n",
        "    #     bn_axis = 3\n",
        "    # else:\n",
        "    #     bn_axis = 1\n",
        "\n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
        "                          'has been changed since Keras 2.2.0.')\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='resnet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auX6gWuGYO2y"
      },
      "source": [
        "model = ResNet50(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=(img_rows, img_cols, 1),\n",
        "             pooling=None,\n",
        "             classes=n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1crXaj1Us8Az"
      },
      "source": [
        "## **GRAY RESNET50**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk6ItmD9s61j"
      },
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "import keras.backend as K\n",
        "from keras.utils import layer_utils\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "  \n",
        "    filters1, filters2, filters3 = filters\n",
        "    bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size,\n",
        "               padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "   \n",
        "    filters1, filters2, filters3 = filters\n",
        "    bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
        "               name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same',\n",
        "               name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
        "                      name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def grayResNet50(include_top=True, weights=None,\n",
        "             input_tensor=None, input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=2):\n",
        "    if weights not in {'imagenet', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `imagenet` '\n",
        "                         '(pre-training on ImageNet).')\n",
        "\n",
        "    #if weights == 'imagenet' and include_top and classes != 15:\n",
        "    #    raise ValueError('If using `weights` as imagenet with `include_top`'\n",
        "    #                     ' as true, `classes` should be 15')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    img_input = Input(shape=input_shape)\n",
        "    \n",
        "    bn_axis = 1\n",
        "\n",
        "    x = ZeroPadding2D((3, 3))(img_input)\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    x = AveragePooling2D((3, 3), name='avg_pool')(x)\n",
        "\n",
        "    if include_top:\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(classes, activation='softmax', name='fc2')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='resnet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQC4U132t4oy"
      },
      "source": [
        "model = grayResNet50(include_top=True,\n",
        "            input_shape=(img_rows, img_cols, 1),\n",
        "            classes=n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQdVz0KsocrK"
      },
      "source": [
        "## VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lO7DUmkoceE"
      },
      "source": [
        "def VGG16Net(width, height, depth, classes):\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(width, height, depth),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(128,(3,2),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1000,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(17,activation='softmax'))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4UB85cgpB45"
      },
      "source": [
        "model = VGG16Net(img_rows,img_cols,1,n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYMRJtCReqgv"
      },
      "source": [
        "## EDGE　IMPULSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gV3d9UweqBJ"
      },
      "source": [
        "def EDGE(width, height, depth, classes):\n",
        "  model = Sequential()\n",
        "  model.add(layers.Conv2D(32, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same', input_shape=(width, height, 1)))\n",
        "  model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "  model.add(layers.Conv2D(16, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  model.add(layers.Dense(n_class, activation='softmax', name='y_pred'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s37s7rwcibPD"
      },
      "source": [
        "model = EDGE(img_rows,img_cols,1,n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpFV5L7SjHn0"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4damQSPjHBG"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Model create #1\n",
        "def mnist(width, height, depth, classes):\n",
        "  input_shape = (width, height, depth)\n",
        "  model=Sequential()\n",
        "  #Conv1\n",
        "  model.add(Conv2D(filters=16, \n",
        "            kernel_size=(3, 3), \n",
        "            padding=\"same\",  \n",
        "            input_shape=input_shape))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  #Conv2\n",
        "  model.add(Conv2D(filters=32, \n",
        "            kernel_size=(3, 3), \n",
        "            padding=\"same\", \n",
        "            input_shape=input_shape))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  #Conv3\n",
        "  model.add(Conv2D(filters=32, \n",
        "            kernel_size=(3, 3), \n",
        "            padding=\"same\", \n",
        "            input_shape=input_shape))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  #FC1\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  #FC2\n",
        "  model.add(Dense(classes))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5qUvlq-jruQ"
      },
      "source": [
        "model = mnist(img_rows,img_cols,1,n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PK2PMtiflLQ"
      },
      "source": [
        "## EFFNET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pg8aMRnfoEM"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.activations import *\n",
        "from keras.callbacks import *\n",
        "\n",
        "\n",
        "def get_post(x_in):\n",
        "    # x = LeakyReLU()(x_in)\n",
        "    x = BatchNormalization()(x_in)\n",
        "    return x\n",
        "\n",
        "def get_block(x_in, ch_in, ch_out):\n",
        "    x = Conv2D(ch_in,\n",
        "               kernel_size=(1, 1),\n",
        "               padding='same',\n",
        "               use_bias=False)(x_in)\n",
        "    x = get_post(x)\n",
        "\n",
        "    x = DepthwiseConv2D(kernel_size=(1, 3), padding='same', use_bias=False)(x)\n",
        "    x = get_post(x)\n",
        "    x = MaxPool2D(pool_size=(2, 1),\n",
        "                  strides=(2, 1))(x) # Separable pooling\n",
        "\n",
        "    x = DepthwiseConv2D(kernel_size=(3, 1),\n",
        "                        padding='same',\n",
        "                        use_bias=False)(x)\n",
        "    x = get_post(x)\n",
        "\n",
        "    x = Conv2D(ch_out,\n",
        "               kernel_size=(2, 1),\n",
        "               strides=(1, 2),\n",
        "               padding='same',\n",
        "               use_bias=False)(x)\n",
        "    x = get_post(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def Effnet(input_shape, nb_classes, include_top=True, weights=None):\n",
        "    x_in = Input(shape=input_shape)\n",
        "\n",
        "    x = get_block(x_in, 32, 64)\n",
        "    x = get_block(x, 64, 128)\n",
        "    x = get_block(x, 128, 256)\n",
        "\n",
        "    if include_top:\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(nb_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=x_in, outputs=x)\n",
        "\n",
        "    if weights is not None:\n",
        "        model.load_weights(weights, by_name=True)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZPFsOADfrm-"
      },
      "source": [
        "model = Effnet((img_rows,img_cols,1),n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulI1jCs5vhRu"
      },
      "source": [
        "## Mobil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvzEm6rIvkHQ"
      },
      "source": [
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.activations import *\n",
        "from keras.callbacks import *\n",
        "\n",
        "\n",
        "def get_conv_block(tensor, channels, strides, alpha=1.0, name=''):\n",
        "    channels = int(channels * alpha)\n",
        "\n",
        "    x = Conv2D(channels,\n",
        "               kernel_size=(3, 3),\n",
        "               strides=strides,\n",
        "               use_bias=False,\n",
        "               padding='same',\n",
        "               name='{}_conv'.format(name))(tensor)\n",
        "    x = BatchNormalization(name='{}_bn'.format(name))(x)\n",
        "    x = Activation('relu', name='{}_act'.format(name))(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_dw_sep_block(tensor, channels, strides, alpha=1.0, name=''):\n",
        "    \"\"\"Depthwise separable conv: A Depthwise conv followed by a Pointwise conv.\"\"\"\n",
        "    channels = int(channels * alpha)\n",
        "\n",
        "    # Depthwise\n",
        "    x = DepthwiseConv2D(kernel_size=(3, 3),\n",
        "                        strides=strides,\n",
        "                        use_bias=False,\n",
        "                        padding='same',\n",
        "                        name='{}_dw'.format(name))(tensor)\n",
        "    x = BatchNormalization(name='{}_bn1'.format(name))(x)\n",
        "    x = Activation('relu', name='{}_act1'.format(name))(x)\n",
        "\n",
        "    # Pointwise\n",
        "    x = Conv2D(channels,\n",
        "               kernel_size=(1, 1),\n",
        "               strides=(1, 1),\n",
        "               use_bias=False,\n",
        "               padding='same',\n",
        "               name='{}_pw'.format(name))(x)\n",
        "    x = BatchNormalization(name='{}_bn2'.format(name))(x)\n",
        "    x = Activation('relu', name='{}_act2'.format(name))(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def MobileNet(shape, num_classes, alpha=1.0, include_top=True, weights=None):\n",
        "    x_in = Input(shape=shape)\n",
        "\n",
        "    x = get_conv_block(x_in, 32, (2, 2), alpha=alpha, name='initial')\n",
        "\n",
        "    layers = [\n",
        "        (64, (1, 1)),\n",
        "        (128, (2, 2)),\n",
        "        (128, (1, 1)),\n",
        "        (256, (2, 2)),\n",
        "        (256, (1, 1)),]\n",
        "    #     (512, (2, 2)),\n",
        "    #     *[(512, (1, 1)) for _ in range(5)],\n",
        "    #     (1024, (2, 2)),\n",
        "    #     (1024, (2, 2))\n",
        "    # ]\n",
        "\n",
        "    for i, (channels, strides) in enumerate(layers):\n",
        "        x = get_dw_sep_block(x, channels, strides, alpha=alpha, name='block{}'.format(i))\n",
        "\n",
        "    if include_top:\n",
        "        x = GlobalAvgPool2D(name='global_avg')(x)\n",
        "        x = Dense(num_classes, activation='softmax', name='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=x_in, outputs=x)\n",
        "\n",
        "    if weights is not None:\n",
        "        model.load_weights(weights, by_name=True)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X78LNCYHvxr4"
      },
      "source": [
        "model = MobileNet((img_rows,img_cols,1),n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arxGCmITgyQx"
      },
      "source": [
        "# **Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H25vwTlPfkEM"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKHiEzJeGemz"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_sOACBPHD3B"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "steps_per_epoch = image_count // BATCH_SIZE\n",
        "validation_steps = image_count*0.2 // BATCH_SIZE\n",
        "\n",
        "print('steps_per_epoch:', steps_per_epoch)\n",
        "print('validation_steps:', validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u-46vQQu-Nd"
      },
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_IhNGfmMPrc"
      },
      "source": [
        "epoch = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox6JWUF_HmZ5"
      },
      "source": [
        "history = model.fit(trainingSet_Batch,\n",
        "           validation_data=testingSet_Batch,\n",
        "           epochs=epoch, \n",
        "           validation_steps=validation_steps,\n",
        "           verbose=2)\n",
        "          #  callbacks=[early_stopping],\n",
        "          #  steps_per_epoch=steps_per_epoch,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gt3xgxXvYjt"
      },
      "source": [
        "# Plot history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCupNIXBMLab"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWxIiB-Hg7pj"
      },
      "source": [
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='lower right')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgCsEqXhvhs4"
      },
      "source": [
        "# Predict image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJYLlOlDWjhs"
      },
      "source": [
        "!pip install opencv-python\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06DgFT8EWp1m"
      },
      "source": [
        "predictimg = random.choice(all_image_paths)\n",
        "print(predictimg)\n",
        "img = cv2.imread('./'+predictimg,cv2.IMREAD_UNCHANGED)\n",
        "# gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "cv2_imshow(img)\n",
        "gray = cv2.resize(img, (img_rows, img_cols), interpolation=cv2.INTER_CUBIC)\n",
        "reshapeimg = gray.reshape(1,img_rows, img_cols, 1) \n",
        "transimg = reshapeimg.astype('float32')\n",
        "predict = model.predict(transimg)\n",
        "print(predict)\n",
        "print(np.argmax(predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzDds8jRWrmX"
      },
      "source": [
        "# Save weights of this model\n",
        "model.save_weights('./my_modelmobilmixset.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX_gppxtvl1H"
      },
      "source": [
        "# Draw confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPqGlICqaA44"
      },
      "source": [
        "## Prepare Evaluation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPR_pfXdJm2f"
      },
      "source": [
        "%%time\n",
        "zip_path = '/content/drive/MyDrive/ARC _AIoT 共用雲端/datasetmix0722.zip'\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q datasetmix0722.zip -d './testingdata'\n",
        "!rm datasetmix0722.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7PnrXP0Kk92"
      },
      "source": [
        "testingdata_root = pathlib.Path('./testingdata')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3B6s08XKh7w"
      },
      "source": [
        "for item in testingdata_root.iterdir():\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eigyjWJKQlC"
      },
      "source": [
        "test_image_paths = list(testingdata_root.glob('*/*')) \n",
        "test_image_paths = [str(path) for path in test_image_paths]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdSgQ9LZK2Jq"
      },
      "source": [
        "testinglabel_names = sorted(item.name for item in testingdata_root.glob('*/') if item.is_dir())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHb5Qe5wLBlR"
      },
      "source": [
        "testinglabel_to_index = dict((name, index) for index, name in enumerate(testinglabel_names))\n",
        "testinglabel_to_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv1Nfnp1LLRZ"
      },
      "source": [
        "test_image_labels = [testinglabel_to_index[pathlib.Path(path).parent.name] for path in test_image_paths]\n",
        "\n",
        "testing_labels = to_categorical(test_image_labels, n_class, dtype = 'float32')\n",
        "print(\"First 10 labels indices: \", test_image_labels[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjWsi-1jyoBT"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "randomlist = random.sample(range(0, image_count), int(image_count)) \n",
        "y_predict = []\n",
        "y_true = test_image_labels\n",
        "for i,j in enumerate(test_image_paths):\n",
        "  img = cv2.imread('./'+j,cv2.IMREAD_UNCHANGED)\n",
        "  gray = cv2.resize(img, (img_rows, img_cols), interpolation=cv2.INTER_CUBIC)\n",
        "  reshapeimg = gray.reshape(1,img_rows, img_cols, 1) \n",
        "  transimg = reshapeimg.astype('float32')\n",
        "  y_predict.append(np.argmax(model.predict(transimg)))\n",
        "target_names = ['0', '1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSMFYwK354f6"
      },
      "source": [
        "print(classification_report(y_true, y_predict, target_names=target_names))\n",
        "print (\"**************************************************************\")\n",
        "\n",
        "plt.figure()\n",
        "cnf_matrix = confusion_matrix(y_true, y_predict)\n",
        "plot_confusion_matrix(cnf_matrix, classes=target_names,normalize=True,\n",
        "                    title='confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}